# Cache

## 缓存架构设计

缓存一般使用内存来进行存储，性能会远优于从硬盘进行读写，所以天然具备高性能和高并发两大优势，一般常用于加速读写和降低存储层负载。

在设计缓存方案时，同样需要从高性能、高并发、高可用三个角度进行衡量，结合业务特性进行设计，并在此基础上额外考虑成本问题。

针对于各项衡量指标，其主要影响因素如下所示：

<table style="width:100%; text-align:center;">
    <tr>
        <th></th>
        <th>衡量指标</th>
        <th>影响因素</th>
    </tr>
    <tr>
        <th rowspan="6">高性能</th>
        <td rowspan="3">读写性能</td>
        <td>内存读取速率</td>
    </tr>
    <tr>
        <td>数据结构</td>
    </tr>
    <tr>
        <td>序列化/反序列化</td>
    </tr>
    <tr>
        <td rowspan="2">命中率</td>
        <td>缓存大小</td>
    </tr>
    <tr>
        <td>淘汰策略</td>
    </tr>
    <tr>
        <td>网络延迟</td>
        <td>集群分布</td>
    </tr>
    <tr>
        <th rowspan="6">高并发</th>
        <td rowspan="3">一致性</td>
        <td>缓存一致性协议</td>
    </tr>
    <tr>
        <td>缓存策略</td>
    </tr>
    <tr>
        <td>主从同步</td>
    </tr>
    <tr>
        <td rowspan="2">负载均衡</td>
        <td>分布式架构</td>
    </tr>
    <tr>
        <td>负载均衡算法</td>
    </tr>
    <tr>
        <td>并发控制</td>
        <td>事务</td>
    </tr>
    <tr>
        <th rowspan="5">高可用</th>
        <td rowspan="2">容错机制</td>
        <td>数据备份</td>
    </tr>
    <tr>
        <td>数据持久化</td>
    </tr>
    <tr>
        <td rowspan="2">故障转移</td>
        <td>主从架构</td>
    </tr>
    <tr>
        <td>哨兵机制</td>
    </tr>
    <tr>
        <td>监控</td>
        <td>实时监控与报警</td>
    </tr>
</table>

## 缓存策略

缓存策略，也被称作缓存模式，即 Cache Pattern，定义了应用层、缓存层、存储层之间的交互方式，包括读写顺序与更新策略。

### Cache Aside

Cache Aside 是最常用的一种缓存策略，其主要流程如下

- 读取缓存层命中：

  - 返回缓存中的数据

- 读取缓存层未命中：

  - 从存储层中读取数据并返回
  - 更新缓存层数据

- 更新数据：

  - 更新存储层数据
  - 删除缓存层数据

其中较为重点的是更新策略，一定要先更新存储层数据，再删除缓存层数据，通过下一次读请求重新构建缓存，才能较好地保障数据一致性。

#### 先删除缓存层，再更新存储层

在读请求和写请求按照如下顺序触发：

- 先触发写请求的删除逻辑，
  - 删除缓存层数据

- 再触发读请求的逻辑
  - 缓存层未命中，读取存储层
  - 返回读取的数据 Old
  - 更新缓存层为老数据 Old

- 最后触发写请求的更新逻辑
  - 将新数据 New 写入存储层

最终，存储层内存储的是新数据 New，缓存层内存储的是读请求更新的老数据 Old，两者存在不一致的情况。

#### 先更新存储层，再删除缓存层

当读请求和写请求按照如下顺序触发：

- 先触发读请求的读取逻辑
  - 缓存层未命中，读取存储层
  - 返回读取的数据 Old

- 然后触发写请求
  - 将新数据 New 写入存储层
  - 删除缓存层数据

- 最后触发读请求的更新逻辑
  - 更新缓存层为老数据 Old

最终，缓存层与存储层仍然存在数据不一致的情况，但是“更新缓存层”与“更新存储层”两个操作相比，前者会远快于后者，所以“先更新再删除”的策略下，最终数据不一致的概率极低，同样也远低于“先删除再更新”的策略。

#### 更新缓存层，而不是删除缓存层

当两个写请求按照如下顺序触发：

- A 请求先更新存储层
- B 请求更新存储层，并更新缓存层
- A 请求再更新缓存层

最终，缓存层与存储层同样存在数据不一致的问题。

将“更新缓存层”的操作替换为“删除缓存层”，可以保障在写请求并发时，缓存层不受影响，因为最终的结果一定是删除缓存层数据。此外，将“删除缓存层”的操作替换为“更新缓存层”时，对于上述提到的两个操作顺序问题，也不会带来额外影响，所以从保障数据一致性的角度来说，最优的方案是在写操作时，删除缓存层数据，而非更新缓存层数据。

此外，我们还可以通过引入互斥锁，避免写请求的并发问题，再将“删除缓存层”的操作替换为“更新缓存层”，该操作可以在写多读少的场景下，提高缓存的利用率，也可以解决存储层由于主从延迟导致的脏数据问题。

#### 删除缓存层失败

主要解决方案有两种：

- 事务：保障缓存层与存储层操作在同一个事务中，但是实现逻辑复杂，不推荐。
- 延迟双删：在同步删除缓存层数据时，额外引入一次异步删除，确保最终删除成功。
  - 异步删除的时机可以通过消息队列或是订阅存储层通知来实现。

对于 mysql 来说，可以通过订阅 binlog 日志来执行异步删除。且这种方案，还可以缓存数据库主从延迟导致的缓存层读取旧数据的问题。对于延迟删除的时间，过长会导致缓存利用率下降，过短同样会受数据库主从延时影响，可以直接设置为主从延迟的时间。

### Read/Write Through

这种方案的重点，在于应用层仅与缓存层交互，与数据层交互的部分，完全由缓存层负责。

- Read Through：读操作时，如果缓存层未命中，由缓存层负责查询存储层，然后先将数据更新至缓存层后再返回。
- Write Through：写操作时，直接更新缓存层，由缓存层更新存储层。

上述两种逻辑，能够保障较高的数据一致性，但是在缓存层与存储层交互的逻辑，有着较高的复杂度，在更新缓存时，也需要保障并发安全。

### Write Back/Behind

在应用层更新数据时，只更新缓存，并立即返回，稍后异步批量更新存储层。

这种方案在更新地效率上是最高的，但是会存在丢数据的情况。

### Refresh Ahead

在读取数据时，如果缓存层将要过期，则通过后台线程，主动触发一次更新操作，将存储层更新至缓存层，并刷新数据过期时间。在读多写少的场景，可以有效提升缓存命中率。

### 总结对比

| 缓存策略            | 性能 | 一致性 | 命中率 | 复杂度 | 业务复杂度 |
| :----------------: | :--: | :---: | :----: | :---: | :-------: |
| Cache Aside        | B    | B     | C      | A     | B         |
| Read/Write Through | C    | A     | A      | C     | A         |
| Write Back/Behind  | A    | C     | B      | B     | C         |
| Refresh Ahead      | B-   | B+    | C+     | A-    | B         |

> 复杂度越低，评级越高，即 A 代表复杂度最低

- 性能:
  - (B) Cache Aside：未命中或更新时，需要访问存储层
  - (C) Read/Write Through：更新时需要加锁保障缓存的并发安全
  - (A) Write Back/Behind：更新时无需同步访问存储层
  - (B-)Cache Aside：接近 Cache Aside，但是读请求可能需要异步更新缓存

- 一致性:
  - (B) Cache Aside：极小概率出现不一致的情况
  - (A) Read/Write Through：业务层只与缓存层交互，能保障强一致性
  - (C) Write Back/Behind：异步更新存储层，可能会丢数据
  - (B+)Cache Aside：略优于 Cache Aside，额外多了更新时机

- 命中率:
  - (C) Cache Aside：更新后会额外删除缓存
  - (A) Read/Write Through：仅与淘汰策略有关，且一般不会过期
  - (B) Write Back/Behind：仅与淘汰策略有关，数据可能过期
  - (C+)Cache Aside：优于 Cache Aside，部分情况会提前更新快过期数据

- 复杂度:
  - (A) Cache Aside：无特殊处理
  - (C) Read/Write Through：需要完全覆盖与存储层的交互，且保障缓存的并发安全
  - (B) Write Back/Behind：需要通过异步任务更新存储层
  - (A-)Cache Aside：接近 Cache Aside，但是读请求可能需要异步更新缓存

- 业务复杂度:
  - (B) Cache Aside：缓存未命中或更新数据时，需要业务层与存储层交互
  - (A) Read/Write Through：业务层仅与缓存层交互
  - (C) Write Back/Behind：与 Cache Aside 相同，且需要额外考虑数据丢失问题
  - (B) Cache Aside：与 Cache Aside 相同

## 常见问题

### 缓存雪崩

大量数据同时过期或者缓存层服务故障，从而导致大量请求直接访问存储层，进而导致系统崩溃。

#### 打散过期时间

在设置数据的过期时间时，加上随机数，避免同时过期。

#### 互斥锁

在处理业务请求时，如果缓存未命中，则添加互斥锁，仅由该次请求去读取存储层，重新构建缓存。在缓存更新成功后，释放互斥锁，需要注意互斥锁的超时时间。

对于未获取到锁的请求，可以考虑等待锁释放后，重新读取缓存，或是直接返回默认值。

#### 永不过期

不再设置缓存的有效期，由专门的后台线程，通过定时任务等方式处理更新逻辑。

对于由淘汰策略等情况导致的缓存失效，一种方式是由后台线程轮询检查缓存是否有效，另一种方式是业务线程发现缓存失效后，通过消息队列通知后台线程触发更新逻辑。

#### 缓存降级

一般情况下，当缓存失效时，请求会继续访问源数据，当流量较大时，会导致下游服务异常并引起雪崩问题。

此时可通过动态配置，例如在流量远大于缓存或存储层的吞吐量时，如果缓存失效，则直接返回默认值，或者缓存一个默认值，保护下游服务。对于后者，需要重点考虑空数据的资源占用问题，以及缓存与存储层的数据不一致的问题。

上述提到的“互斥锁”与“永不过期”两种方案中，对于缓存失效时的处理方案，也是缓存降级方案的一种体现。

#### 服务熔断或限流

缓存中间件的性能会远远高于存储层，当大量请求击穿缓存，去请求存储层时，极大概率存储层服务是无法承受的，并有可能会进一步影响其他上游服务。所以当雪崩发生时，最有效的方案是服务的限流和熔断。

对于限流来说，需要综合存储层可以承受的最大 QPS 来判断限流值，避免本服务的存储层出现问题，也避免其他依赖该存储层的服务出现问题。常见的限流算法有令牌桶算法和漏桶算法等。

对于熔断来说，当下游服务（包括本服务访问的缓存层服务、存储层服务）出现问题时，相关异常错误率会飙升，此时可以在服务内触发熔断，丢弃部分对于下游的请求，缓解下游压力。

#### 提高服务可用性

多集群、多机房。

### 缓存击穿

缓存中的所有数据，仍然符合二八法则，80% 的请求访问集中在其中 20% 的数据，这部分数据也可被称作热点数据。

当热点数据过期时，或者缓存中未缓存热点数据，此时仍会有大量请求直接访问存储层。

#### 互斥锁、永不过期、缓存降级

缓存穿透也可看作是缓存雪崩的某种特殊情况，仍然可以使用“互斥锁”、“永不过期”、“缓存降级”来进行防护。

#### 预热数据

对于已知的热数据新上线的情况，例如每天轮换的首页资源，可以在系统上线前，提前对相关数据进行预热，加载进缓存中。避免系统冷启动时，大量热点数据缓存未命中的情况。

### 缓存穿透

用户想要访问的数据，既不存在于缓存中，也不存在于存储层中，此时同样会导致大量请求直接访问存储层。

这种情况一般主要有两个原因导致，存储层数据丢失，例如误操作导致删库，或者请求参数异常，例如黑灰产恶意攻击、上游链路出现 bug 等。

#### 缓存降级

存储层本身不存在数据，所以缓存处直接处理，返回默认值或存储默认值即可，没有必要继续访问存储层。

#### 布隆过滤器

在访问缓存或是访问存储层之前，将存在的 key 值用布隆过滤器提前存储，用于拦截大部分 key 不存在的情况。

在引入布隆过滤器后，需要额外考虑新增 key 值的同步问题，避免布隆过滤器与缓存或是与存储层不一致的情况，所以适用于数据相对固定的场景。

### 总结对比

缓存雪崩、缓存击穿、缓存穿透，三种问题最终的表现都比较一致，大量请求通过缓存后，继续访问存储层，导致下游存储层服务异常，但是导致问题的原因略有不同：

- 缓存雪崩：由于大量 key 值同时过期，或是缓存服务异常，导致服务整体可用性下降，侧重点在于整体

  - 首要考虑的是避免问题，通过“打散过期时间”来避免前者，通过“提高服务可用性”来避免后者
  - 其次要考虑单个 key 维度的解决方案，通过“互斥锁”、“永不过期”、“缓存降级”的方式，减小下游服务的压力
  - 最后要考虑整体服务的解决方案，通过“服务熔断或限流”，缓解问题

- 缓存击穿：由于热点数据缓存未命中导致，与缓存雪崩中大量 key 值同时过期较为类似，侧重点在于部分热点数据

  - 首要考虑避免问题，通过“预热数据”，避免系统冷启动时数据不存在的情况
  - 然后是热 key 过期问题，通过“互斥锁”、“永不过期”、“缓存降级”的方式进行缓解

- 缓存穿透：由于存储层本身不存在相关数据，缓存不可用导致，侧重点在于无法构建缓存

  - 首要考虑避免问题，通过“布隆过滤器”提前进行判断，避免访问缓存服务、存储层服务
  - 然后是解决问题，通过“缓存降级”的方式，将问题留在缓存层，避免存储层服务异常

即：

<table>
    <tr>
        <th>异常问题</th>
        <th>产生原因</th>
        <th>解决方案</th>
    </tr>
    <tr>
        <th rowspan="4">缓存雪崩</th>
        <td rowspan="2">大量 key 同时过期</td>
        <td>预防：打散过期时间</td>
    </tr>
    <tr>
        <td>解决：互斥锁、永不过期、缓存降级</td>
    </tr>
    <tr>
        <td rowspan="2">缓存服务异常</td>
        <td>预防：提高服务可用性</td>
    </tr>
    <tr>
        <td>解决：服务限流或熔断</td>
    </tr>
    <tr>
        <th rowspan="2">缓存击穿</th>
        <td rowspan="2">热点数据未命中</td>
        <td>预防：预热数据</td>
    </tr>
    <tr>
        <td>解决：互斥锁、永不过期、缓存降级</td>
    </tr>
    <tr>
        <th rowspan="2">缓存穿透</th>
        <td rowspan="2">存储层不存在相关数据</td>
        <td>预防：布隆过滤器</td>
    </tr>
    <tr>
        <td>解决：缓存降级</td>
    </tr>
</table>

## Web 系统缓存层级

- 客户端/前端缓存
- 负载均衡缓存
- CDN 缓存
- 服务端本地缓存
- 分布式缓存（Redis）
- 存储层缓存（数据库缓存）

## 参考

- <https://zhuanlan.zhihu.com/p/591436083>
- <https://en.wikipedia.org/wiki/Cache_replacement_policies>
